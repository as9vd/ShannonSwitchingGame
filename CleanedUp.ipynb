{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f4de6d-969d-430a-bf51-5c71b6f585b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Node and Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "07e9a0ec-88c0-43e8-9db3-361b7654124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, val):\n",
    "        self.val = val # Value of node = its position (left, right, zigzag, continue).\n",
    "        self.adj_list = set()\n",
    "\n",
    "# create a list of edges for Game\n",
    "class Graph:\n",
    "    def __init__(self, num_rows, num_cols):\n",
    "        self.num_rows = num_rows\n",
    "        self.num_cols = num_cols\n",
    "        self.nodes_int = self._create_nodes()\n",
    "        \n",
    "        self.edges = set()\n",
    "        for row in range(self.num_rows): # Kinda like initialising a 2D matrix. From the nodes generated, add the edges to the set.\n",
    "            for col in range(self.num_cols):\n",
    "                node = self.nodes_mat[row][col]\n",
    "                \n",
    "                adj_list = self.mapper[node.val].adj_list\n",
    "                node = self.mapper[node.val]\n",
    "                for other_node in adj_list:\n",
    "                    self.edges.add((node, other_node))\n",
    "                    self.edges.add((other_node, node))\n",
    "        \n",
    "    def init_start_and_end(self):\n",
    "        self.start = 1 # top-left\n",
    "        self.end = self.num_rows * self.num_cols # bottom-right\n",
    "        \n",
    "    def _create_nodes(self):\n",
    "        nodes_int, i = [], 1\n",
    "        nodes = [[Node((row, col)) for col in range(self.num_cols)] for row in range(self.num_rows)] \n",
    "        mapper = dict()\n",
    "        int_mapper = dict()\n",
    "        for row in range(self.num_rows):\n",
    "            for col in range(self.num_cols):\n",
    "                node = Node(i) # Create the nodes, number 1 to (m * n).\n",
    "                nodes_int.append(node)\n",
    "                mapper[(row, col)] = node\n",
    "                int_mapper[i] = node\n",
    "                i += 1\n",
    "        \n",
    "        for row in range(self.num_rows):\n",
    "            for col in range(self.num_cols):\n",
    "                node = nodes[row][col] # this stuff below is where we initialise the neighbours.\n",
    "                if row > 0:\n",
    "                    node.adj_list.add(nodes[row - 1][col])  # Upper neighbour.\n",
    "                    nodes[row - 1][col].adj_list.add(node)\n",
    "                    \n",
    "                    current_mapping = mapper[(row, col)]\n",
    "                    nbr_mapping = mapper[(row - 1, col)]\n",
    "                    \n",
    "                    current_mapping.adj_list.add(nbr_mapping)\n",
    "                    nbr_mapping.adj_list.add(current_mapping)\n",
    "                    \n",
    "                if row < self.num_rows - 1:\n",
    "                    node.adj_list.add(nodes[row + 1][col])  # Lower neighbour.\n",
    "                    nodes[row + 1][col].adj_list.add(node)\n",
    "                    \n",
    "                    current_mapping = mapper[(row, col)]\n",
    "                    nbr_mapping = mapper[(row + 1, col)]\n",
    "                    \n",
    "                    current_mapping.adj_list.add(nbr_mapping)\n",
    "                    nbr_mapping.adj_list.add(current_mapping)\n",
    "                    \n",
    "                if col > 0:\n",
    "                    node.adj_list.add(nodes[row][col - 1])  # Left neighbour.\n",
    "                    nodes[row][col - 1].adj_list.add(node)\n",
    "                    \n",
    "                    current_mapping = mapper[(row, col)]\n",
    "                    nbr_mapping = mapper[(row, col - 1)]\n",
    "                    \n",
    "                    current_mapping.adj_list.add(nbr_mapping)\n",
    "                    nbr_mapping.adj_list.add(current_mapping)\n",
    "                    \n",
    "                if col < self.num_cols - 1:\n",
    "                    node.adj_list.add(nodes[row][col + 1])  # Right neighbour.\n",
    "                    nodes[row][col + 1].adj_list.add(node)\n",
    "                    \n",
    "                    current_mapping = mapper[(row, col)]\n",
    "                    nbr_mapping = mapper[(row, col + 1)]\n",
    "                    \n",
    "                    current_mapping.adj_list.add(nbr_mapping)\n",
    "                    nbr_mapping.adj_list.add(current_mapping)\n",
    "                \n",
    "        self.nodes_mat = nodes\n",
    "        self.mapper = mapper\n",
    "        self.int_mapper = int_mapper\n",
    "                    \n",
    "        return nodes_int\n",
    "        \n",
    "    def print_graph(self): # for debugging purposes\n",
    "        print([node.val for row in self.nodes_mat for node in row])\n",
    "        print()\n",
    "        print([node.val for node in self.nodes_int])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a396c4a-9076-4996-8736-187dcec31000",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GameAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "10e7b04c-3fec-4b39-a9d5-3afd6dd7b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class GameAI:\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        self.m = self.graph.num_rows\n",
    "        self.n = self.graph.num_cols\n",
    "        \n",
    "        self.node_mapping = dict()\n",
    "        for i in range(1, (self.m * self.n) + 1):\n",
    "            self.node_mapping[i] = self.graph.nodes_int[i - 1] # e.g. 1 is in index 0, 2 is index 1, etc.\n",
    "        \n",
    "        self.edges = []\n",
    "        for i in range(1, (self.graph.num_rows * self.graph.num_cols) + 1):\n",
    "            adj_list = [node.val for node in self.graph.int_mapper[i].adj_list]\n",
    "            for adj_node in adj_list:\n",
    "                if (adj_node, i) in self.edges:\n",
    "                    continue\n",
    "                self.edges.append((i, adj_node))\n",
    "        \n",
    "        self.edges = sorted(self.edges)\n",
    "        \n",
    "        self.unsecured_count = (2 * self.m * self.n) - self.m - self.n # this is for the CUT player\n",
    "        self.secured_edges = [] # fix  \n",
    "        self.removed_edges = [] # cut\n",
    "        \n",
    "        self.remaining = {(node1.val, node2.val) for node1, node2 in self.graph.edges} \n",
    "        self.fix_win = False\n",
    "        self.end = False\n",
    "        \n",
    "    def reset(self): # Reset everything for the next training iteration.\n",
    "        self.unsecured_count = (2 * self.m * self.n) - self.m - self.n \n",
    "        self.secured_edges = []\n",
    "        self.removed_edges = []\n",
    "        \n",
    "        self.remaining = {(node1.val, node2.val) for node1, node2 in self.graph.edges} \n",
    "        self.fix_win = False\n",
    "        self.end = False\n",
    "        \n",
    "    # This is what our AI will train against. Random shit.\n",
    "    def choose_edge_to_cut(self):\n",
    "        edge_to_cut = random.choice(list(self.remaining))\n",
    "        return edge_to_cut    \n",
    "    \n",
    "    # Plays step-by-step. This is what we'll use for \"learning\".\n",
    "    def next_step_player(self, chosen_edge):\n",
    "        if self.unsecured_count > 0 and not self.end:\n",
    "            if not self.end:\n",
    "                # 1. FIX player's turn: where the magic happens. (HE NOW GOES FIRST)\n",
    "                if len(self.remaining) == 0:\n",
    "                    # No more valid edges to choose.\n",
    "                    self.fix_win = False\n",
    "                    self.end = True\n",
    "                else:\n",
    "                    self.fix(chosen_edge)\n",
    "            \n",
    "            if self.is_fix_path_complete():\n",
    "                self.fix_win = True\n",
    "                self.end = True\n",
    "                return\n",
    "                \n",
    "            # 2. CUT/bot player's turn.\n",
    "            if not self.end:\n",
    "                if len(self.remaining) == 0:\n",
    "                    # No more valid edges to choose.\n",
    "                    self.fix_win = False\n",
    "                    self.end = True\n",
    "                else:\n",
    "                    edge_to_cut = self.choose_edge_to_cut()\n",
    "                    self.cut(edge_to_cut)\n",
    "                    \n",
    "            if len(self.remaining) == 0:\n",
    "                self.end = True\n",
    "        else:\n",
    "            self.end = True\n",
    "\n",
    "    def is_fix_path_complete(self): # This does BFS to check if there is a path from the start to the end.\n",
    "        visited = set()\n",
    "        stack = [1]\n",
    "\n",
    "        while stack:\n",
    "            current_node = stack.pop()\n",
    "            if current_node == self.m * self.n: # e.g. 4x4, 16 is the bottom-right.\n",
    "                return True\n",
    "\n",
    "            if current_node not in visited:\n",
    "                visited.add(current_node)\n",
    "                adj_list = self.node_mapping[current_node].adj_list\n",
    "                \n",
    "                for nbr in adj_list:\n",
    "                    edge = (current_node, nbr.val)\n",
    "                    reverse_edge = (nbr.val, current_node)\n",
    "\n",
    "                    if edge in self.secured_edges or reverse_edge in self.secured_edges:\n",
    "                        if nbr.val not in visited:\n",
    "                            stack.append(nbr.val)\n",
    "\n",
    "        return False\n",
    "    \n",
    "    # 1. FIX player's function; secures unsecured edge in question (and its reverse).\n",
    "    def fix(self, edge):\n",
    "        # edge = ex: (1, 4)\n",
    "        if edge in self.remaining:\n",
    "            self.remaining.remove(edge)\n",
    "            self.secured_edges.append(edge)\n",
    "            self.unsecured_count -= 1\n",
    "            \n",
    "        # Also remove the reverse direction of the edge.\n",
    "        reverse_edge = (edge[1], edge[0])\n",
    "        if reverse_edge in self.remaining:\n",
    "            self.remaining.remove(reverse_edge)\n",
    "\n",
    "    # 2. CUT player's function; removes unsecured edge in question (and its reverse).\n",
    "    def cut(self, edge):\n",
    "        # edge = ex: (1, 4)\n",
    "        if edge in self.remaining:\n",
    "            self.remaining.remove(edge)\n",
    "            self.removed_edges.append(edge)\n",
    "            self.unsecured_count -= 1\n",
    "            \n",
    "        # Also remove the reverse direction of the edge.\n",
    "        reverse_edge = (edge[1], edge[0])\n",
    "        if reverse_edge in self.remaining:\n",
    "            self.remaining.remove(reverse_edge)\n",
    "  \n",
    "    # Reward function\n",
    "    def get_reward(self):\n",
    "        if self.fix_win:\n",
    "            # Positive reward when the FIX player wins\n",
    "            reward = 1.0\n",
    "        elif self.end:\n",
    "            # Negative reward when the FIX player loses\n",
    "            reward = -1.0\n",
    "        else:\n",
    "            # Intermediate reward for the ongoing game\n",
    "            reward = 0.0            \n",
    "\n",
    "        return reward\n",
    "            \n",
    "    def get_state(self):\n",
    "        # Define the state representation based on the game state.\n",
    "        secured_count = len(self.secured_edges)\n",
    "        remaining_count = self.unsecured_count\n",
    "        secured_edges = self.secured_edges\n",
    "        deleted_edges = self.removed_edges\n",
    "        remaining_edges = list(self.remaining) # Yet for this, we'll keep the reverse edges. Bit hypocritical, but fuck it.\n",
    "        \n",
    "        state = (secured_edges, deleted_edges, remaining_edges, secured_count, remaining_count)\n",
    "    \n",
    "        return state\n",
    "    \n",
    "    # This is still here purely for debugging purposes.\n",
    "    def play(self):\n",
    "        while self.unsecured_count > 0:\n",
    "            # 1. CUT player's turn\n",
    "            if len(self.remaining) == 0:\n",
    "                # No more valid edges to choose.\n",
    "                self.fix_win = False\n",
    "                self.end = True\n",
    "                break\n",
    "                \n",
    "            edge_to_cut = self.choose_edge_to_cut()\n",
    "            self.cut(edge_to_cut)\n",
    "        \n",
    "            # 2. FIX player's turn\n",
    "            if len(self.remaining) == 0:\n",
    "                # No more valid edges to choose.\n",
    "                self.fix_win = False\n",
    "                self.end = True\n",
    "\n",
    "            edge_to_fix = self.choose_edge_to_fix()\n",
    "            self.fix(edge_to_fix)\n",
    "            \n",
    "            if self.is_fix_path_complete():\n",
    "                self.fix_win = True\n",
    "                self.end = True\n",
    "                break\n",
    "            elif self.unsecured_count == 0:\n",
    "                self.fix_win = False\n",
    "                self.end = True\n",
    "\n",
    "    # This is still here purely for debugging purposes.\n",
    "    def choose_edge_to_fix(self):\n",
    "        edge_to_fix = random.choice(list(self.remaining))\n",
    "        return edge_to_fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3a5c02-68b8-4d8f-b4fd-f062a7ef4e5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "81054043-5201-470e-8b17-dac2c3aa61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. model.py\n",
    "# 2. agent.py\n",
    "# model is the FFNN, agent is what trains the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# This is the Feedforward Neural Network.\n",
    "class ShannonModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, edges, game):\n",
    "        self.edges = edges\n",
    "        self.game = game\n",
    "        \n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        sorted_x, indices = torch.sort(x, descending = True)\n",
    "        max_probability = None\n",
    "        chosen_edge = None\n",
    "    \n",
    "        for index in indices:\n",
    "            edge = self.edges[index.item()]\n",
    "            reverse_edge = (edge[1], edge[0])\n",
    "            \n",
    "            # Could be a problem here. Don't know what, but just troubleshooting for future.\n",
    "            if ((edge not in self.game.removed_edges and edge not in self.game.secured_edges) and \n",
    "                (reverse_edge not in self.game.removed_edges and reverse_edge not in self.game.secured_edges)): \n",
    "                # print(\"Edge:\", edge, \"Removed:\", game.removed_edges, \"Secured:\", game.secured_edges)\n",
    "                max_probability = x[index]\n",
    "                chosen_edge = edge\n",
    "                break\n",
    "                \n",
    "        return x, max_probability, chosen_edge # Return the probabilities and the valid edge with the max probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f24d5-3892-48e1-9174-4290412836f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f8edbac2-da83-408e-a90f-9244cda27360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from collections import deque\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "def format_state(state):\n",
    "    num_nodes = find_max_number([state[0], state[1], state[2]])\n",
    "        \n",
    "    secured_edges = convert_to_adj_matrix(state[0], num_nodes)\n",
    "    deleted_edges = convert_to_adj_matrix(state[1], num_nodes)\n",
    "    remaining_edges = convert_to_adj_matrix(state[2], num_nodes)\n",
    "    secured_count, remaining_count = state[3], state[4]\n",
    "        \n",
    "    secured_edges, deleted_edges, remaining_edges, secured_count, remaining_count = (torch.tensor(secured_edges).flatten(), \n",
    "                                                                                     torch.tensor(deleted_edges).flatten(), \n",
    "                                                                                     torch.tensor(remaining_edges).flatten(), \n",
    "                                                                                     torch.tensor([secured_count]), \n",
    "                                                                                     torch.tensor([remaining_count]))\n",
    "            \n",
    "    formatted_state = np.concatenate([secured_edges, deleted_edges, remaining_edges, secured_count, remaining_count]).tolist()\n",
    "    formatted_state = torch.tensor(formatted_state)\n",
    "    \n",
    "    return formatted_state\n",
    "\n",
    "def convert_to_adj_matrix(edges, num_nodes):\n",
    "    nodes = set()\n",
    "    for edge in edges:\n",
    "        nodes.add(edge[0])\n",
    "        nodes.add(edge[1])\n",
    "\n",
    "    adj_matrix = np.zeros((num_nodes + 1, num_nodes + 1)) # 0th col and 0th row will just be to pad.\n",
    "\n",
    "    # Populate the adjacency matrix\n",
    "    for edge in edges:\n",
    "        adj_matrix[edge[0]][edge[1]] = 1\n",
    "        \n",
    "    return adj_matrix\n",
    "\n",
    "def find_max_number(lists_of_tuples):\n",
    "    max_number = float('-inf')\n",
    "\n",
    "    for list_of_tuples in lists_of_tuples:\n",
    "        for tup in list_of_tuples:\n",
    "            numbers = [x for x in tup if isinstance(x, (int, float))]\n",
    "            if numbers:\n",
    "                current_max = max(numbers)\n",
    "                if current_max > max_number:\n",
    "                    max_number = current_max\n",
    "\n",
    "    return max_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8a8c9d0a-c1c5-401a-b5f1-6d4dc98ee772",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/512, Loss: 0.0031\n",
      "Epoch: 2/512, Loss: 0.0012\n",
      "Epoch: 3/512, Loss: 0.0026\n",
      "Epoch: 4/512, Loss: 0.0004\n",
      "Epoch: 5/512, Loss: 0.7156\n",
      "Epoch: 6/512, Loss: 0.0060\n",
      "Epoch: 7/512, Loss: 0.7488\n",
      "Epoch: 8/512, Loss: 0.0008\n",
      "Epoch: 9/512, Loss: 0.4214\n",
      "Epoch: 10/512, Loss: 2.2766\n",
      "Epoch: 11/512, Loss: 0.0125\n",
      "Epoch: 12/512, Loss: 0.0256\n",
      "Epoch: 13/512, Loss: 0.0000\n",
      "Epoch: 14/512, Loss: 0.0003\n",
      "Epoch: 15/512, Loss: 2.6585\n",
      "Epoch: 16/512, Loss: 0.0008\n",
      "Epoch: 17/512, Loss: 0.0001\n",
      "Epoch: 18/512, Loss: 0.0536\n",
      "Epoch: 19/512, Loss: 0.0018\n",
      "Epoch: 20/512, Loss: 0.0003\n",
      "Epoch: 21/512, Loss: 0.4842\n",
      "Epoch: 22/512, Loss: 0.0004\n",
      "Epoch: 23/512, Loss: 0.0002\n",
      "Epoch: 24/512, Loss: 0.0016\n",
      "Epoch: 25/512, Loss: 0.0008\n",
      "Epoch: 26/512, Loss: 0.1354\n",
      "Epoch: 27/512, Loss: 0.0005\n",
      "Epoch: 28/512, Loss: 0.0001\n",
      "Epoch: 29/512, Loss: 0.0005\n",
      "Epoch: 30/512, Loss: 0.0005\n",
      "Epoch: 31/512, Loss: 0.0002\n",
      "Epoch: 32/512, Loss: 0.0070\n",
      "Epoch: 33/512, Loss: 0.0000\n",
      "Epoch: 34/512, Loss: 0.0011\n",
      "Epoch: 35/512, Loss: 0.3557\n",
      "Epoch: 36/512, Loss: 0.0060\n",
      "Epoch: 37/512, Loss: 0.0104\n",
      "Epoch: 38/512, Loss: 0.0192\n",
      "Epoch: 39/512, Loss: 3.7793\n",
      "Epoch: 40/512, Loss: 0.0003\n",
      "Epoch: 41/512, Loss: 0.0002\n",
      "Epoch: 42/512, Loss: 0.4386\n",
      "Epoch: 43/512, Loss: 0.0002\n",
      "Epoch: 44/512, Loss: 0.0002\n",
      "Epoch: 45/512, Loss: 0.1663\n",
      "Epoch: 46/512, Loss: 2.6938\n",
      "Epoch: 47/512, Loss: 0.0013\n",
      "Epoch: 48/512, Loss: 0.3014\n",
      "Epoch: 49/512, Loss: 0.0018\n",
      "Epoch: 50/512, Loss: 4.0696\n",
      "Epoch: 51/512, Loss: 0.0002\n",
      "Epoch: 52/512, Loss: 0.0191\n",
      "Epoch: 53/512, Loss: 0.0112\n",
      "Epoch: 54/512, Loss: 0.0054\n",
      "Epoch: 55/512, Loss: 0.0051\n",
      "Epoch: 56/512, Loss: 0.0324\n",
      "Epoch: 57/512, Loss: 0.0007\n",
      "Epoch: 58/512, Loss: 0.0013\n",
      "Epoch: 59/512, Loss: 0.0061\n",
      "Epoch: 60/512, Loss: 0.1804\n",
      "Epoch: 61/512, Loss: 0.0082\n",
      "Epoch: 62/512, Loss: 0.0001\n",
      "Epoch: 63/512, Loss: 0.1617\n",
      "Epoch: 64/512, Loss: 0.0002\n",
      "Epoch: 65/512, Loss: 0.0004\n",
      "Epoch: 66/512, Loss: 0.0434\n",
      "Epoch: 67/512, Loss: 0.0002\n",
      "Epoch: 68/512, Loss: 0.0109\n",
      "Epoch: 69/512, Loss: 2.7433\n",
      "Epoch: 70/512, Loss: 0.0409\n",
      "Epoch: 71/512, Loss: 0.1748\n",
      "Epoch: 72/512, Loss: 0.0013\n",
      "Epoch: 73/512, Loss: 0.0004\n",
      "Epoch: 74/512, Loss: 0.0007\n",
      "Epoch: 75/512, Loss: 0.0026\n",
      "Epoch: 76/512, Loss: 0.0002\n",
      "Epoch: 77/512, Loss: 0.0001\n",
      "Epoch: 78/512, Loss: 0.0036\n",
      "Epoch: 79/512, Loss: 0.0022\n",
      "Epoch: 80/512, Loss: 0.0003\n",
      "Epoch: 81/512, Loss: 0.0002\n",
      "Epoch: 82/512, Loss: 0.0077\n",
      "Epoch: 83/512, Loss: 0.0073\n",
      "Epoch: 84/512, Loss: 0.0098\n",
      "Epoch: 85/512, Loss: 0.0124\n",
      "Epoch: 86/512, Loss: 0.0013\n",
      "Epoch: 87/512, Loss: 0.0099\n",
      "Epoch: 88/512, Loss: 4.1237\n",
      "Epoch: 89/512, Loss: 0.0727\n",
      "Epoch: 90/512, Loss: 0.0215\n",
      "Epoch: 91/512, Loss: 0.0161\n",
      "Epoch: 92/512, Loss: 0.0605\n",
      "Epoch: 93/512, Loss: 0.0006\n",
      "Epoch: 94/512, Loss: 0.0003\n",
      "Epoch: 95/512, Loss: 0.1322\n",
      "Epoch: 96/512, Loss: 0.0148\n",
      "Epoch: 97/512, Loss: 0.0231\n",
      "Epoch: 98/512, Loss: 0.0237\n",
      "Epoch: 99/512, Loss: 0.0007\n",
      "Epoch: 100/512, Loss: 0.0095\n",
      "Epoch: 101/512, Loss: 0.0147\n",
      "Epoch: 102/512, Loss: 0.0051\n",
      "Epoch: 103/512, Loss: 0.0265\n",
      "Epoch: 104/512, Loss: 0.0089\n",
      "Epoch: 105/512, Loss: 0.0007\n",
      "Epoch: 106/512, Loss: 0.0138\n",
      "Epoch: 107/512, Loss: 0.0918\n",
      "Epoch: 108/512, Loss: 0.0141\n",
      "Epoch: 109/512, Loss: 0.0010\n",
      "Epoch: 110/512, Loss: 0.0043\n",
      "Epoch: 111/512, Loss: 0.0026\n",
      "Epoch: 112/512, Loss: 0.0002\n",
      "Epoch: 113/512, Loss: 0.0077\n",
      "Epoch: 114/512, Loss: 0.0463\n",
      "Epoch: 115/512, Loss: 0.1181\n",
      "Epoch: 116/512, Loss: 0.0000\n",
      "Epoch: 117/512, Loss: 0.0015\n",
      "Epoch: 118/512, Loss: 0.0156\n",
      "Epoch: 119/512, Loss: 0.0087\n",
      "Epoch: 120/512, Loss: 0.0016\n",
      "Epoch: 121/512, Loss: 0.0003\n",
      "Epoch: 122/512, Loss: 0.0036\n",
      "Epoch: 123/512, Loss: 0.0103\n",
      "Epoch: 124/512, Loss: 0.0088\n",
      "Epoch: 125/512, Loss: 0.0001\n",
      "Epoch: 126/512, Loss: 0.0006\n",
      "Epoch: 127/512, Loss: 0.0016\n",
      "Epoch: 128/512, Loss: 0.0120\n",
      "Epoch: 129/512, Loss: 0.0426\n",
      "Epoch: 130/512, Loss: 3.0204\n",
      "Epoch: 131/512, Loss: 0.0027\n",
      "Epoch: 132/512, Loss: 0.0031\n",
      "Epoch: 133/512, Loss: 0.2707\n",
      "Epoch: 134/512, Loss: 0.0054\n",
      "Epoch: 135/512, Loss: 0.0016\n",
      "Epoch: 136/512, Loss: 0.0041\n",
      "Epoch: 137/512, Loss: 0.0054\n",
      "Epoch: 138/512, Loss: 0.0076\n",
      "Epoch: 139/512, Loss: 0.0122\n",
      "Epoch: 140/512, Loss: 2.7902\n",
      "Epoch: 141/512, Loss: 0.0132\n",
      "Epoch: 142/512, Loss: 0.0009\n",
      "Epoch: 143/512, Loss: 0.0001\n",
      "Epoch: 144/512, Loss: 0.1909\n",
      "Epoch: 145/512, Loss: 0.0000\n",
      "Epoch: 146/512, Loss: 0.0001\n",
      "Epoch: 147/512, Loss: 0.0238\n",
      "Epoch: 148/512, Loss: 0.0966\n",
      "Epoch: 149/512, Loss: 0.0095\n",
      "Epoch: 150/512, Loss: 0.0131\n",
      "Epoch: 151/512, Loss: 0.0001\n",
      "Epoch: 152/512, Loss: 0.0090\n",
      "Epoch: 153/512, Loss: 0.0001\n",
      "Epoch: 154/512, Loss: 0.0079\n",
      "Epoch: 155/512, Loss: 0.0083\n",
      "Epoch: 156/512, Loss: 0.0009\n",
      "Epoch: 157/512, Loss: 0.0000\n",
      "Epoch: 158/512, Loss: 0.0010\n",
      "Epoch: 159/512, Loss: 0.0075\n",
      "Epoch: 160/512, Loss: 0.0001\n",
      "Epoch: 161/512, Loss: 0.0023\n",
      "Epoch: 162/512, Loss: 0.0183\n",
      "Epoch: 163/512, Loss: 0.0058\n",
      "Epoch: 164/512, Loss: 0.0017\n",
      "Epoch: 165/512, Loss: 0.0020\n",
      "Epoch: 166/512, Loss: 0.0035\n",
      "Epoch: 167/512, Loss: 0.0001\n",
      "Epoch: 168/512, Loss: 0.0000\n",
      "Epoch: 169/512, Loss: 0.0028\n",
      "Epoch: 170/512, Loss: 0.1071\n",
      "Epoch: 171/512, Loss: 0.0063\n",
      "Epoch: 172/512, Loss: 0.1479\n",
      "Epoch: 173/512, Loss: 0.0002\n",
      "Epoch: 174/512, Loss: 0.0003\n",
      "Epoch: 175/512, Loss: 0.0018\n",
      "Epoch: 176/512, Loss: 0.0038\n",
      "Epoch: 177/512, Loss: 0.0704\n",
      "Epoch: 178/512, Loss: 0.0001\n",
      "Epoch: 179/512, Loss: 0.0011\n",
      "Epoch: 180/512, Loss: 0.0009\n",
      "Epoch: 181/512, Loss: 0.0067\n",
      "Epoch: 182/512, Loss: 0.0001\n",
      "Epoch: 183/512, Loss: 0.0548\n",
      "Epoch: 184/512, Loss: 0.0012\n",
      "Epoch: 185/512, Loss: 0.0003\n",
      "Epoch: 186/512, Loss: 0.0078\n",
      "Epoch: 187/512, Loss: 0.0140\n",
      "Epoch: 188/512, Loss: 0.0020\n",
      "Epoch: 189/512, Loss: 0.0221\n",
      "Epoch: 190/512, Loss: 0.0282\n",
      "Epoch: 191/512, Loss: 0.0096\n",
      "Epoch: 192/512, Loss: 0.0001\n",
      "Epoch: 193/512, Loss: 0.0003\n",
      "Epoch: 194/512, Loss: 0.0083\n",
      "Epoch: 195/512, Loss: 0.0001\n",
      "Epoch: 196/512, Loss: 0.0003\n",
      "Epoch: 197/512, Loss: 0.0016\n",
      "Epoch: 198/512, Loss: 2.1668\n",
      "Epoch: 199/512, Loss: 0.0011\n",
      "Epoch: 200/512, Loss: 0.0082\n",
      "Epoch: 201/512, Loss: 0.0013\n",
      "Epoch: 202/512, Loss: 0.0003\n",
      "Epoch: 203/512, Loss: 0.0023\n",
      "Epoch: 204/512, Loss: 0.0027\n",
      "Epoch: 205/512, Loss: 0.0000\n",
      "Epoch: 206/512, Loss: 0.0065\n",
      "Epoch: 207/512, Loss: 0.0009\n",
      "Epoch: 208/512, Loss: 0.0004\n",
      "Epoch: 209/512, Loss: 0.0013\n",
      "Epoch: 210/512, Loss: 0.3409\n",
      "Epoch: 211/512, Loss: 0.0027\n",
      "Epoch: 212/512, Loss: 0.0034\n",
      "Epoch: 213/512, Loss: 0.0005\n",
      "Epoch: 214/512, Loss: 0.0065\n",
      "Epoch: 215/512, Loss: 0.0000\n",
      "Epoch: 216/512, Loss: 0.0000\n",
      "Epoch: 217/512, Loss: 0.0002\n",
      "Epoch: 218/512, Loss: 0.0038\n",
      "Epoch: 219/512, Loss: 0.0006\n",
      "Epoch: 220/512, Loss: 0.2273\n",
      "Epoch: 221/512, Loss: 0.0091\n",
      "Epoch: 222/512, Loss: 0.0001\n",
      "Epoch: 223/512, Loss: 0.0075\n",
      "Epoch: 224/512, Loss: 0.0001\n",
      "Epoch: 225/512, Loss: 0.0017\n",
      "Epoch: 226/512, Loss: 0.0010\n",
      "Epoch: 227/512, Loss: 0.0004\n",
      "Epoch: 228/512, Loss: 1.9293\n",
      "Epoch: 229/512, Loss: 0.0008\n",
      "Epoch: 230/512, Loss: 0.0010\n",
      "Epoch: 231/512, Loss: 0.0001\n",
      "Epoch: 232/512, Loss: 0.0000\n",
      "Epoch: 233/512, Loss: 0.2555\n",
      "Epoch: 234/512, Loss: 0.2111\n",
      "Epoch: 235/512, Loss: 0.0021\n",
      "Epoch: 236/512, Loss: 0.0028\n",
      "Epoch: 237/512, Loss: 0.2866\n",
      "Epoch: 238/512, Loss: 0.0005\n",
      "Epoch: 239/512, Loss: 0.0001\n",
      "Epoch: 240/512, Loss: 0.0010\n",
      "Epoch: 241/512, Loss: 0.0009\n",
      "Epoch: 242/512, Loss: 0.1552\n",
      "Epoch: 243/512, Loss: 0.0002\n",
      "Epoch: 244/512, Loss: 0.0011\n",
      "Epoch: 245/512, Loss: 0.0001\n",
      "Epoch: 246/512, Loss: 0.0000\n",
      "Epoch: 247/512, Loss: 0.0010\n",
      "Epoch: 248/512, Loss: 0.0001\n",
      "Epoch: 249/512, Loss: 0.0007\n",
      "Epoch: 250/512, Loss: 0.0032\n",
      "Epoch: 251/512, Loss: 0.0003\n",
      "Epoch: 252/512, Loss: 0.1633\n",
      "Epoch: 253/512, Loss: 0.0028\n",
      "Epoch: 254/512, Loss: 0.0028\n",
      "Epoch: 255/512, Loss: 0.0028\n",
      "Epoch: 256/512, Loss: 0.2015\n",
      "Epoch: 257/512, Loss: 0.0014\n",
      "Epoch: 258/512, Loss: 0.0000\n",
      "Epoch: 259/512, Loss: 0.0018\n",
      "Epoch: 260/512, Loss: 0.0013\n",
      "Epoch: 261/512, Loss: 0.0030\n",
      "Epoch: 262/512, Loss: 0.2006\n",
      "Epoch: 263/512, Loss: 0.0009\n",
      "Epoch: 264/512, Loss: 0.1871\n",
      "Epoch: 265/512, Loss: 2.1664\n",
      "Epoch: 266/512, Loss: 0.0016\n",
      "Epoch: 267/512, Loss: 0.0006\n",
      "Epoch: 268/512, Loss: 0.1715\n",
      "Epoch: 269/512, Loss: 0.0004\n",
      "Epoch: 270/512, Loss: 0.1240\n",
      "Epoch: 271/512, Loss: 0.0079\n",
      "Epoch: 272/512, Loss: 0.0106\n",
      "Epoch: 273/512, Loss: 0.0021\n",
      "Epoch: 274/512, Loss: 0.0000\n",
      "Epoch: 275/512, Loss: 2.2092\n",
      "Epoch: 276/512, Loss: 0.0001\n",
      "Epoch: 277/512, Loss: 0.0002\n",
      "Epoch: 278/512, Loss: 0.0001\n",
      "Epoch: 279/512, Loss: 0.1366\n",
      "Epoch: 280/512, Loss: 0.0002\n",
      "Epoch: 281/512, Loss: 0.0055\n",
      "Epoch: 282/512, Loss: 0.1735\n",
      "Epoch: 283/512, Loss: 0.0080\n",
      "Epoch: 284/512, Loss: 0.0006\n",
      "Epoch: 285/512, Loss: 0.0000\n",
      "Epoch: 286/512, Loss: 0.0001\n",
      "Epoch: 287/512, Loss: 0.0001\n",
      "Epoch: 288/512, Loss: 0.1295\n",
      "Epoch: 289/512, Loss: 0.0001\n",
      "Epoch: 290/512, Loss: 0.2394\n",
      "Epoch: 291/512, Loss: 0.0000\n",
      "Epoch: 292/512, Loss: 0.0003\n",
      "Epoch: 293/512, Loss: 0.0001\n",
      "Epoch: 294/512, Loss: 0.0002\n",
      "Epoch: 295/512, Loss: 0.0004\n",
      "Epoch: 296/512, Loss: 0.0002\n",
      "Epoch: 297/512, Loss: 0.1618\n",
      "Epoch: 298/512, Loss: 0.0013\n",
      "Epoch: 299/512, Loss: 0.1947\n",
      "Epoch: 300/512, Loss: 0.0017\n",
      "Epoch: 301/512, Loss: 0.0006\n",
      "Epoch: 302/512, Loss: 0.0112\n",
      "Epoch: 303/512, Loss: 0.0006\n",
      "Epoch: 304/512, Loss: 0.0002\n",
      "Epoch: 305/512, Loss: 0.0003\n",
      "Epoch: 306/512, Loss: 0.1826\n",
      "Epoch: 307/512, Loss: 0.0025\n",
      "Epoch: 308/512, Loss: 0.0085\n",
      "Epoch: 309/512, Loss: 0.1228\n",
      "Epoch: 310/512, Loss: 0.0034\n",
      "Epoch: 311/512, Loss: 0.0000\n",
      "Epoch: 312/512, Loss: 0.1151\n",
      "Epoch: 313/512, Loss: 0.0002\n",
      "Epoch: 314/512, Loss: 0.0601\n",
      "Epoch: 315/512, Loss: 0.0006\n",
      "Epoch: 316/512, Loss: 0.0002\n",
      "Epoch: 317/512, Loss: 0.0024\n",
      "Epoch: 318/512, Loss: 0.0000\n",
      "Epoch: 319/512, Loss: 0.0011\n",
      "Epoch: 320/512, Loss: 0.0000\n",
      "Epoch: 321/512, Loss: 0.0003\n",
      "Epoch: 322/512, Loss: 0.0002\n",
      "Epoch: 323/512, Loss: 0.1076\n",
      "Epoch: 324/512, Loss: 0.0034\n",
      "Epoch: 325/512, Loss: 0.0034\n",
      "Epoch: 326/512, Loss: 0.0000\n",
      "Epoch: 327/512, Loss: 0.0004\n",
      "Epoch: 328/512, Loss: 0.0000\n",
      "Epoch: 329/512, Loss: 0.0005\n",
      "Epoch: 330/512, Loss: 0.0008\n",
      "Epoch: 331/512, Loss: 0.0110\n",
      "Epoch: 332/512, Loss: 0.0001\n",
      "Epoch: 333/512, Loss: 0.0034\n",
      "Epoch: 334/512, Loss: 0.0003\n",
      "Epoch: 335/512, Loss: 0.0000\n",
      "Epoch: 336/512, Loss: 0.0012\n",
      "Epoch: 337/512, Loss: 0.0002\n",
      "Epoch: 338/512, Loss: 0.1093\n",
      "Epoch: 339/512, Loss: 0.0002\n",
      "Epoch: 340/512, Loss: 0.0010\n",
      "Epoch: 341/512, Loss: 0.0001\n",
      "Epoch: 342/512, Loss: 0.0022\n",
      "Epoch: 343/512, Loss: 0.0013\n",
      "Epoch: 344/512, Loss: 0.0038\n",
      "Epoch: 345/512, Loss: 0.0001\n",
      "Epoch: 346/512, Loss: 0.0001\n",
      "Epoch: 347/512, Loss: 0.0656\n",
      "Epoch: 348/512, Loss: 0.0001\n",
      "Epoch: 349/512, Loss: 0.0117\n",
      "Epoch: 350/512, Loss: 0.0008\n",
      "Epoch: 351/512, Loss: 0.1418\n",
      "Epoch: 352/512, Loss: 0.0001\n",
      "Epoch: 353/512, Loss: 0.0014\n",
      "Epoch: 354/512, Loss: 0.0006\n",
      "Epoch: 355/512, Loss: 0.0001\n",
      "Epoch: 356/512, Loss: 0.0007\n",
      "Epoch: 357/512, Loss: 0.0015\n",
      "Epoch: 358/512, Loss: 0.0000\n",
      "Epoch: 359/512, Loss: 0.0031\n",
      "Epoch: 360/512, Loss: 0.0049\n",
      "Epoch: 361/512, Loss: 0.0000\n",
      "Epoch: 362/512, Loss: 0.0001\n",
      "Epoch: 363/512, Loss: 0.0000\n",
      "Epoch: 364/512, Loss: 0.1148\n",
      "Epoch: 365/512, Loss: 0.0000\n",
      "Epoch: 366/512, Loss: 0.1540\n",
      "Epoch: 367/512, Loss: 0.0490\n",
      "Epoch: 368/512, Loss: 0.0002\n",
      "Epoch: 369/512, Loss: 0.0045\n",
      "Epoch: 370/512, Loss: 0.0001\n",
      "Epoch: 371/512, Loss: 0.0001\n",
      "Epoch: 372/512, Loss: 0.0018\n",
      "Epoch: 373/512, Loss: 0.0007\n",
      "Epoch: 374/512, Loss: 0.0008\n",
      "Epoch: 375/512, Loss: 0.0022\n",
      "Epoch: 376/512, Loss: 0.0006\n",
      "Epoch: 377/512, Loss: 0.0771\n",
      "Epoch: 378/512, Loss: 0.0001\n",
      "Epoch: 379/512, Loss: 0.0002\n",
      "Epoch: 380/512, Loss: 0.0088\n",
      "Epoch: 381/512, Loss: 0.0685\n",
      "Epoch: 382/512, Loss: 0.0006\n",
      "Epoch: 383/512, Loss: 0.0114\n",
      "Epoch: 384/512, Loss: 0.0023\n",
      "Epoch: 385/512, Loss: 0.0028\n",
      "Epoch: 386/512, Loss: 0.0024\n",
      "Epoch: 387/512, Loss: 0.0013\n",
      "Epoch: 388/512, Loss: 0.0029\n",
      "Epoch: 389/512, Loss: 0.0000\n",
      "Epoch: 390/512, Loss: 0.0734\n",
      "Epoch: 391/512, Loss: 0.0008\n",
      "Epoch: 392/512, Loss: 0.0028\n",
      "Epoch: 393/512, Loss: 0.0001\n",
      "Epoch: 394/512, Loss: 0.0079\n",
      "Epoch: 395/512, Loss: 0.0063\n",
      "Epoch: 396/512, Loss: 0.0178\n",
      "Epoch: 397/512, Loss: 0.0001\n",
      "Epoch: 398/512, Loss: 0.0003\n",
      "Epoch: 399/512, Loss: 0.0000\n",
      "Epoch: 400/512, Loss: 0.0012\n",
      "Epoch: 401/512, Loss: 0.0002\n",
      "Epoch: 402/512, Loss: 0.0000\n",
      "Epoch: 403/512, Loss: 0.0102\n",
      "Epoch: 404/512, Loss: 0.0001\n",
      "Epoch: 405/512, Loss: 0.0000\n",
      "Epoch: 406/512, Loss: 0.0004\n",
      "Epoch: 407/512, Loss: 0.0007\n",
      "Epoch: 408/512, Loss: 2.9507\n",
      "Epoch: 409/512, Loss: 0.1287\n",
      "Epoch: 410/512, Loss: 0.0000\n",
      "Epoch: 411/512, Loss: 0.0198\n",
      "Epoch: 412/512, Loss: 0.0002\n",
      "Epoch: 413/512, Loss: 0.0024\n",
      "Epoch: 414/512, Loss: 0.0000\n",
      "Epoch: 415/512, Loss: 0.0005\n",
      "Epoch: 416/512, Loss: 0.0002\n",
      "Epoch: 417/512, Loss: 0.0017\n",
      "Epoch: 418/512, Loss: 0.0025\n",
      "Epoch: 419/512, Loss: 0.0067\n",
      "Epoch: 420/512, Loss: 0.0326\n",
      "Epoch: 421/512, Loss: 0.0912\n",
      "Epoch: 422/512, Loss: 0.0002\n",
      "Epoch: 423/512, Loss: 0.0029\n",
      "Epoch: 424/512, Loss: 0.0015\n",
      "Epoch: 425/512, Loss: 0.0000\n",
      "Epoch: 426/512, Loss: 0.0253\n",
      "Epoch: 427/512, Loss: 0.0071\n",
      "Epoch: 428/512, Loss: 0.0014\n",
      "Epoch: 429/512, Loss: 0.0017\n",
      "Epoch: 430/512, Loss: 0.0000\n",
      "Epoch: 431/512, Loss: 0.0044\n",
      "Epoch: 432/512, Loss: 0.0000\n",
      "Epoch: 433/512, Loss: 0.0007\n",
      "Epoch: 434/512, Loss: 0.0006\n",
      "Epoch: 435/512, Loss: 0.0041\n",
      "Epoch: 436/512, Loss: 0.0008\n",
      "Epoch: 437/512, Loss: 0.0001\n",
      "Epoch: 438/512, Loss: 0.0001\n",
      "Epoch: 439/512, Loss: 0.0039\n",
      "Epoch: 440/512, Loss: 0.0001\n",
      "Epoch: 441/512, Loss: 0.0014\n",
      "Epoch: 442/512, Loss: 0.0073\n",
      "Epoch: 443/512, Loss: 0.0367\n",
      "Epoch: 444/512, Loss: 0.0001\n",
      "Epoch: 445/512, Loss: 0.0993\n",
      "Epoch: 446/512, Loss: 0.0002\n",
      "Epoch: 447/512, Loss: 0.0000\n",
      "Epoch: 448/512, Loss: 0.0000\n",
      "Epoch: 449/512, Loss: 0.0064\n",
      "Epoch: 450/512, Loss: 0.0019\n",
      "Epoch: 451/512, Loss: 0.0837\n",
      "Epoch: 452/512, Loss: 0.0030\n",
      "Epoch: 453/512, Loss: 0.0002\n",
      "Epoch: 454/512, Loss: 0.0003\n",
      "Epoch: 455/512, Loss: 0.0088\n",
      "Epoch: 456/512, Loss: 0.0084\n",
      "Epoch: 457/512, Loss: 0.0001\n",
      "Epoch: 458/512, Loss: 0.0001\n",
      "Epoch: 459/512, Loss: 0.0001\n",
      "Epoch: 460/512, Loss: 0.1540\n",
      "Epoch: 461/512, Loss: 0.0014\n",
      "Epoch: 462/512, Loss: 0.0021\n",
      "Epoch: 463/512, Loss: 0.0101\n",
      "Epoch: 464/512, Loss: 0.0001\n",
      "Epoch: 465/512, Loss: 3.1797\n",
      "Epoch: 466/512, Loss: 0.0013\n",
      "Epoch: 467/512, Loss: 0.0011\n",
      "Epoch: 468/512, Loss: 0.0023\n",
      "Epoch: 469/512, Loss: 0.0357\n",
      "Epoch: 470/512, Loss: 0.0047\n",
      "Epoch: 471/512, Loss: 0.0013\n",
      "Epoch: 472/512, Loss: 0.0002\n",
      "Epoch: 473/512, Loss: 0.0001\n",
      "Epoch: 474/512, Loss: 0.0001\n",
      "Epoch: 475/512, Loss: 0.0021\n",
      "Epoch: 476/512, Loss: 0.0016\n",
      "Epoch: 477/512, Loss: 0.0017\n",
      "Epoch: 478/512, Loss: 0.0002\n",
      "Epoch: 479/512, Loss: 0.0018\n",
      "Epoch: 480/512, Loss: 0.0000\n",
      "Epoch: 481/512, Loss: 0.0004\n",
      "Epoch: 482/512, Loss: 0.0142\n",
      "Epoch: 483/512, Loss: 0.0021\n",
      "Epoch: 484/512, Loss: 0.0000\n",
      "Epoch: 485/512, Loss: 0.0004\n",
      "Epoch: 486/512, Loss: 0.0020\n",
      "Epoch: 487/512, Loss: 0.0069\n",
      "Epoch: 488/512, Loss: 0.0028\n",
      "Epoch: 489/512, Loss: 0.0000\n",
      "Epoch: 490/512, Loss: 0.0019\n",
      "Epoch: 491/512, Loss: 0.0016\n",
      "Epoch: 492/512, Loss: 0.0007\n",
      "Epoch: 493/512, Loss: 2.9990\n",
      "Epoch: 494/512, Loss: 0.0062\n",
      "Epoch: 495/512, Loss: 0.0005\n",
      "Epoch: 496/512, Loss: 0.0010\n",
      "Epoch: 497/512, Loss: 0.0126\n",
      "Epoch: 498/512, Loss: 0.0000\n",
      "Epoch: 499/512, Loss: 0.0015\n",
      "Epoch: 500/512, Loss: 0.0659\n",
      "Epoch: 501/512, Loss: 0.0167\n",
      "Epoch: 502/512, Loss: 0.0001\n",
      "Epoch: 503/512, Loss: 3.5658\n",
      "Epoch: 504/512, Loss: 0.0000\n",
      "Epoch: 505/512, Loss: 0.0000\n",
      "Epoch: 506/512, Loss: 0.0001\n",
      "Epoch: 507/512, Loss: 0.0000\n",
      "Epoch: 508/512, Loss: 0.0000\n",
      "Epoch: 509/512, Loss: 0.0329\n",
      "Epoch: 510/512, Loss: 0.0002\n",
      "Epoch: 511/512, Loss: 0.0006\n",
      "Epoch: 512/512, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Parameters.\n",
    "num_epochs = 512\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "input_size = 302\n",
    "hidden_size = 256\n",
    "output_size = 12\n",
    "gamma = 0.90\n",
    "target_update = 16\n",
    "\n",
    "# Create the Graph and GameAI instances.\n",
    "num_rows = 3\n",
    "num_cols = 3\n",
    "graph = Graph(num_rows, num_cols)\n",
    "game = GameAI(graph)\n",
    "edges = game.edges\n",
    "\n",
    "# Initialize the Feedforward Neural Network (policy network) and target network.\n",
    "policy_net = ShannonModel(input_size, hidden_size, output_size, edges, game)\n",
    "target_net = ShannonModel(input_size, hidden_size, output_size, edges, game)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    state_list = []\n",
    "    action_list = []\n",
    "    reward_list = []\n",
    "    next_state_list = []\n",
    "    done_list = []\n",
    "\n",
    "    while not game.end:\n",
    "        # Get the current state\n",
    "        state = game.get_state()\n",
    "        formatted_state = format_state(state)\n",
    "\n",
    "        # Choose an action using the policy network.\n",
    "        _, _, action = policy_net(formatted_state)\n",
    "\n",
    "        # Perform the action and get the reward\n",
    "        game.next_step_player(action)\n",
    "        reward = game.get_reward()\n",
    "        next_state = game.get_state()\n",
    "        formatted_next_state = format_state(next_state)\n",
    "        done = game.end\n",
    "\n",
    "        # Store the transition\n",
    "        state_list.append(formatted_state)\n",
    "        action_list.append(action)\n",
    "        reward_list.append(reward)\n",
    "        next_state_list.append(formatted_next_state)\n",
    "        done_list.append(done)\n",
    "                \n",
    "    # Reset the game if it has ended\n",
    "    game.reset()\n",
    "\n",
    "    # Create a DataLoader for the collected data\n",
    "    dataset = TensorDataset(torch.stack(state_list), \n",
    "                            torch.tensor(action_list), \n",
    "                            torch.tensor(reward_list, dtype=torch.float32), \n",
    "                            torch.stack(next_state_list), \n",
    "                            torch.tensor(done_list))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Train the policy network\n",
    "    for batch_idx, (states, actions, rewards, next_states, dones) in enumerate(dataloader):\n",
    "        for i in range(len(states)):           \n",
    "            q_values, max_q, chosen_edge = policy_net(states[i])\n",
    "            next_q_values, max_next_q, chosen_next_edge = target_net(next_states[i])\n",
    "            \n",
    "            target_q_values = rewards[i] + (1 - dones[i].float()) * gamma * next_q_values.max()\n",
    "\n",
    "            loss = criterion(q_values, target_q_values.detach())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Update the target network\n",
    "    if epoch % target_update == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9833171a-3c7f-4640-9276-969c651e7690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  3,  9, 10,  0, 11,  5,  6,  2,  1,  8,  7])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([ 4,  3,  9, 10,  0, 11,  5,  6,  2,  1,  8,  7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55cbd5-6bca-4202-b8e2-c47a3e5a4f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
